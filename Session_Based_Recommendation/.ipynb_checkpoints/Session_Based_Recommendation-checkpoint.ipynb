{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<!-- ![sesion](images/session_example.png) -->\n",
    "<img src=\"images/session_example.png\" width=\"600\">\n",
    "<h1>Recomendacion Basada en Sesiones</h1>\n",
    "<h3>Sebastian Prillo</h3>\n",
    "<h4>Miercoles 12 de septiembre de 2018 - Seminario Machin Lenin</h4>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problematica tipica\n",
    "- Un usario navega productos en un sitio de e-commerce. Queremos recomendarle productos que le puedan interesar.\n",
    "<img src=\"images/session_example.png\" width=\"600\">\n",
    "- Metrica de negocio concreto: maximizar el **click-through-rate** (a.k.a. CTR) de nuestro recomendador:\n",
    "$$CTR = \\frac{\\text{# recomendaciones clickeadas}}{\\text{# recomendaciones vistas}}$$\n",
    "(el objetivo podria ser distinto, como maximizar la cantidad de ventas, esto es solo a modo de motivacion para tener una metrica de negocio en la cabeza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Particularidades del problema\n",
    "- El usuario llega a nuestro sitio, navega, compra lo que quiere, y se va. La unidad de trabajo es la **sesion**.\n",
    "- Por que esto no es como recomendar peliculas en Netflix? RTA: Nadie compra 50 celulares en un a√±o.\n",
    "- No tiene sentido construir perfiles de usario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Propuesta para resolver el problema\n",
    "\n",
    "Modelar el problema como uno de **prediccion del proximo termino de una secuencia**.\n",
    "\n",
    "Si tengo un modelo que, dada la historia de navegacion durante la sesion, es capaz de darme una distribucion de probabilidad sobre el proximo producto, puedo usar el top X mas probable como recomendaciones.\n",
    "\n",
    "Entonces, nos proponemos resolver el siguiente problema: Sea $I$ el conjunto de $m$ items (productos), $S^{(i)}$ la $i$-esima sesion de entre $n$, con $S^{(i)} = (S_1^{(i)}, \\dots, S_{l_i}^{(i)}) \\in I^{l_i}$. Buscamos una funcion (modelo)\n",
    "\n",
    "$$f : \\cup_k I^k \\rightarrow Prob(I)$$\n",
    "\n",
    "que dada la secuencia de productos vistos por el usuario durante la sesion, nos de una distribucion de probabilidad sobre el siguiente producto. Objetivo: maximizar ls precision (o precision at K, la metrica que usted guste)\n",
    "\n",
    "**Observacion**: Este problema **no es equivalente al original** (maximizar CTR):\n",
    "- Deseamos que resolver bien el nuevo problema implique resolver bien el original.\n",
    "- La ventaja es que la metrica del problema nuevo (precision) la podemos calcular **facil a partir de datos historicos**, mientras que el CTR no!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cadenas de Markov\n",
    "- Considerar solo el ultimo producto.\n",
    "- Se calcula la matriz de probabilidad de transicion entre productos.\n",
    "\n",
    "Ej: Dadas sesiones:\n",
    "- $\\text{ipod} \\rightarrow \\text{auriculares}$\n",
    "- $\\text{celular} \\rightarrow \\text{auriculares} \\rightarrow \\text{memoria 16GB}$\n",
    "- $\\text{celular} \\rightarrow \\text{memoria 16GB} \\rightarrow \\text{auriculares}$\n",
    "\n",
    "El modelo es:\n",
    "\n",
    "|actual\\siguiente|ipod|celular|auriculares|memoria 16GB|\n",
    "|-|-|-|-|-|\n",
    "|ipod|0.0|0.0|1.0|0.0|\n",
    "|celular|0.0|0.0|0.5|0.5|\n",
    "|auriculares|0.0|0.0|0.0|1.0|\n",
    "|memoria 16GB|0.0|0.0|1.0|0.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cadenas de Markov\n",
    "\n",
    "- Problema:\n",
    "    - Las probabilidades de transicion son solo **estimaciones de la realidad** y son pesimas para los productos que aparecen pocas veces.\n",
    "    - Otra forma de verlo: Sea $t$ la cantidad promedio de transiciones relevantes desde un producto a otro. Entonces el modelo de Markov tiene que aprender $tN$ parametros. La mayoria de ellos se infiere a partir de poca data $\\Rightarrow$ overfitting.\n",
    "\n",
    "<img src=\"images/long_tail.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cadenas de Markov Factorizadas\n",
    "\n",
    "Motivacion: Supongamos que tenemos tres sesiones:\n",
    "- $\\text{celular} \\rightarrow \\text{auricular 1} \\rightarrow \\text{memoria 16 GB}$\n",
    "- $\\text{celular} \\rightarrow \\text{auricular 1} \\rightarrow \\text{memoria 32 GB}$\n",
    "- $\\text{celular} \\rightarrow \\text{auricular 2} \\rightarrow \\text{memoria 16 GB}$\n",
    "\n",
    "Estaria bueno que el modelo se de cuenta solo de que auricular 1 y auricular 2 son **'lo mismo'**. Si lo logramos, todas las transiciones desde/hacia auricular 1 van a contribuir a las estimaciones de las probabilidades de transicion de auricular 2 y viceversa! \n",
    "\n",
    "- Asi aprenderiamos que de auricular 2 podemos transicionar a memoria 32 GB.\n",
    "- Es como si hiciera aparecer data nueva $\\Rightarrow$ reduzco overfitting, generalizo mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Digresion: Embeddings\n",
    "\n",
    "Dado un conjunto $X$ (ej: de productos), un **embedding** es una funcion $emb : X \\rightarrow \\mathbb R^k$.\n",
    "- La idea es que con un embedding bueno, elementos 'semanticamente similares' vayan a parar a vectores similares.\n",
    "- $k$ se llama la **dimension** del embedding.\n",
    "- Hay que definir una nocion de 'similitud' en $\\mathbb R^k$, tipicamente el producto interno. ($sim(u, v) = \\left<u, v\\right>$)\n",
    "\n",
    "Ejemplo: embeddings de dimension 2 para palabras:\n",
    "\n",
    "<img src=\"images/embeddings.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cadenas de Markov Factorizadas\n",
    "\n",
    "- Para cada producto $i$ aprenderemos un embedding $v_i \\in \\mathbb R^k$. La idea va a ser que la probabilidad de transicionar de $i$ a $j$ sea proporcional a $sim(v_i, v_j)$ \n",
    "- En el ejemplo anterior, nos imaginamos algo como:\n",
    "\n",
    "<img src=\"images/embedding_productos.png\" width=\"400\">\n",
    "\n",
    "- Asi, por mas que no observemos una transicion de auricular 2 a memoria 32 GB, si auricular 1 y auricular 2 van a parar cerca, deducimos la transicion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cadenas de Markov Factorizadas\n",
    "\n",
    "Formalizacion: dados los embeddings $v_i$, la probabilidad de transicion del producto $i$ al $j$ en el modelo es\n",
    "\n",
    "$$P(j | i) \\propto\n",
    "e^{\\left<v_i, v_j\\right>}$$\n",
    "\n",
    "O sea,\n",
    "\n",
    "$$P(j | i) = \\frac{e^{\\left<v_i, v_j\\right>}}{\\sum_{k} e^{\\left<v_i, v_k\\right>}}$$\n",
    "\n",
    "tambien conocido como un **softmax**.\n",
    "\n",
    "Ahora maximizar la probabilidad de los datos (bajo el modelo probabilistico obvio asociado):\n",
    "\n",
    "\\begin{align}\n",
    "\\arg \\max_{v_1,\\dots,v_n} P(S^{(1)}, \\dots, S^{(n)}) = \\arg \\max_{v_1,\\dots,v_n}  \\prod_{i = 1}^n \\prod_{j = 1}^{l_i - 1} P({S_j^{(i)}, S_{j+1}^{(i)}})\n",
    "\\end{align}\n",
    "\n",
    "A.K.A. hacer maximum likelihood estimation.\n",
    "\n",
    "**Observacion**: Hacer maximum likelihood **NO** implica maximizar precision, que es lo que nos interesa! Con lo cual tenemos **otro** nivel de simplificacion mas! La ventaja es que el likelihood es una funcion suave de los parametros que quiero optimizar entonces puedo hacer gradient descent.\n",
    "\n",
    "**NOTA**: De hecho, es aceptado que softmax + cross entropy loss es una mala idea en este problema, en general se usa **bayesian pairwise ranking loss**. Correlaciona mejor con precision (etc.), y es mas facil de optimizar / numericamente mas estable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cadenas de Markov Factorizadas\n",
    "\n",
    "<img src=\"images/FMC2.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Recap\n",
    "\n",
    "- Cadenas de Markov: Estimo $P(j|i)$ sin restricciones.\n",
    "- Cadenas de Markov Factorizadas: Restrinjo $P$ tal que $P(j | i) \\propto\n",
    "e^{\\left<v_i, v_j\\right>}$ $\\Rightarrow$ + bias, - variance $\\Rightarrow$ - overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Redes Recurrentes\n",
    "\n",
    "- Generalizan las Cadenas de Markov Factorizadas.\n",
    "- Arma de doble filo: mayor poder expresivo, menor interpretabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Recurrentes\n",
    "\n",
    "<img src=\"images/RNN.png\" width=\"400\">\n",
    "\n",
    "- $i_t$ = input en tiempo $t$.\n",
    "- $h_t$ = estado en tiempo $t$ $= f(h_{t - 1}, i_t)$ para alguna $f$. Ejemplos tipicos de $f$: GRU, LSTM.\n",
    "- $o_t$ = output en tiempo $t$ $= g(h_t)$ para alguna $g$. Ejemplos tipicos de $g$: softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Recurrentes\n",
    "\n",
    "## Cadenas de Markov Factorizadas como Redes Recurrentes\n",
    "\n",
    "<img src=\"images/FMC_as_RNN.png\" width=\"400\">\n",
    "\n",
    "- $i_t = v_t$\n",
    "- $h_t = f(h_{t - 1}, i_t) = i_t$\n",
    "- $o_t = g(h_t) = sotmax(\\left<h_t, v_1\\right>, \\dots, \\left<h_t, v_m\\right>) = softmax(V h_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Recurrentes\n",
    "\n",
    "## Con GRU\n",
    "\n",
    "<img src=\"images/RNN.png\" width=\"400\">\n",
    "\n",
    "- $h_0 = 0$\n",
    "- $i_t = v_t$\n",
    "- $h_t = f(h_{t - 1}, i_t) = (1 - z_t) \\odot h_{t-1} + z_t \\odot \\sigma_h(W_h x_t + U_h(r_t \\odot h_{t-1}) + b_h)$ donde\n",
    "$$z_t = \\sigma_g(W_z x_t + U_z h_{t-1} + b_z)$$\n",
    "$$r_t = \\sigma_g(W_r x_t + U_r h_{t-1} + b_r)$$\n",
    "$$\\sigma_g(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "$$\\sigma_h(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$$\n",
    "- $o_t = g(h_t) = sotmax(\\left<h_t, v_1\\right>, \\dots, \\left<h_t, v_m\\right>) = softmax(V h_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Recurrentes\n",
    "\n",
    "## Algo intermedio\n",
    "\n",
    "<img src=\"images/RNN.png\" width=\"400\">\n",
    "\n",
    "Promedio ponderado de la historia:\n",
    "\n",
    "- $h_0 = v_1$\n",
    "- $i_t = v_t$\n",
    "- $h_t = \\frac{i_t + h_{t-1}}{2}$\n",
    "- $o_t = g(h_t) = sotmax(\\left<h_t, v_1\\right>, \\dots, \\left<h_t, v_m\\right>) = softmax(V h_t)$\n",
    "\n",
    "La diferencia entre esto y la Cadena de Markov Factorizada es que aca usamos\n",
    "\n",
    "$$\\frac{v_1}{2^{t-1}} + \\frac{v_2}{2^{t-1}} + \\frac{v_3}{2^{t-2}} + \\dots + \\frac{v_t}{2}$$\n",
    "\n",
    "para el estado en vez de $v_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
