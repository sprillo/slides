{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<!-- ![sesion](images/session_example.png) -->\n",
    "<img src=\"images/session_example.png\" width=\"600\">\n",
    "<h1>Recomendacion Basada en Sesiones</h1>\n",
    "<h3>Sebastian Prillo</h3>\n",
    "<h4>Miercoles 19 de septiembre de 2018 - Seminario Machin Lenin</h4>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Por que Reco?\n",
    "\n",
    "***[...] the recommendations were used so extensively by Amazon.com that a Microsoft Research report estimated 30 percent of Amazon.com's page views were from recommendations. Similarly, Netflix used recommender systems so extensively that their Chief Product Officer, Neil Hunt, indicated that more than 80 percent of movies watched on Netflix came through recommendations, and placed the value of Netflix recommendations at more than US \\$1 billion per year.*** ([Amazon 2017](https://www.computer.org/csdl/mags/ic/2017/03/mic2017030012.pdf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problematica tipica\n",
    "- Un usario navega productos en un sitio de e-commerce. Queremos recomendarle productos que le puedan interesar.\n",
    "<center>\n",
    "<img src=\"images/session_example.png\" width=\"600\">\n",
    "</center>\n",
    "- Metrica de negocio concreta: maximizar el **click-through-rate** (a.k.a. CTR) de nuestro recomendador:\n",
    "$$CTR = \\frac{\\text{# recomendaciones clickeadas}}{\\text{# recomendaciones vistas}}$$\n",
    "(el objetivo podria ser distinto, como maximizar la cantidad de ventas, esto es solo a modo de motivacion para tener una metrica de negocio en la cabeza)\n",
    "\n",
    "**Pregunta**: Hay alguna forma de estimar el CTR de un modelo sin ponerlo en produccion? (a.k.a. offline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Particularidades del problema\n",
    "\n",
    "No contamos con informacion del usuario, porque:\n",
    "\n",
    "- El usuario no esta loggeado/identificado/autenticado\n",
    "- La informacion historica del usuario no es relevante\n",
    "- etc\n",
    "\n",
    "$\\Rightarrow$ La unidad de trabajo es la **sesion**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Baselines: User-knn?\n",
    "\n",
    "- Para generar recomendaciones para un usuario, busco **usuarios similares** (que tengan muchos productos en comun) y recomiendo los demas productos de esos usuarios.\n",
    "- Los primeros sistemas de recomendacion fueron de este tipo\n",
    "\n",
    "**No podemos usarlo en nuestro problema por motivos obvios**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Baselines: Item-knn\n",
    "\n",
    "- Paper: [Amazon 2003](https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf)\n",
    "- Para cada item, busco **items similares** (que se hayan consumido en simultaneo mas de lo esperado al azar)\n",
    "- Para generar recomendaciones para un usuario, busco items similares a los que consumio.\n",
    "- Escala mucho mejor que user-based CF\n",
    "- Adoptado de forma masiva en la industria\n",
    "\n",
    "Podemos adaptarlo a nuestro problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Baselines: Item-knn\n",
    "\n",
    "Defino la similitud entre dos items como:\n",
    "\n",
    "$$sim(i, j) = \\frac{c_{i,j}}{\\sqrt{c_i} \\sqrt{c_j}}$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$c_i = \\text{cantidad de sesiones donde $i$ aparece}$$\n",
    "\n",
    "$$c_{i,j} = \\text{cantidad de sesiones donde $i$ y $j$ aparecen}$$\n",
    "\n",
    "**Nota**: Hay mas formas posibles de definir la similitud.\n",
    "\n",
    "**Nota**: Hay que tener cuidado con las estimaciones ruidosas.\n",
    "\n",
    "Genero los candidatos mirando los items mas similares a los que aparecieron en la sesion (o al ultimo de la sesion nada mas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Baselines: Item-knn\n",
    "\n",
    "***This baseline is one of the most common item-to-item solutions in practical systems, that provides recommendations in the “others who viewed this item also viewed these ones” setting. Despite of its simplicity it is usually a strong baseline (Linden et al., 2003; Davidson et al., 2010).*** ([Hidasi 2016](https://arxiv.org/pdf/1511.06939.pdf))\n",
    "\n",
    "***The algorithm scales to hundreds of millions of users and tens of millions of items without sampling or other techniques that can reduce the quality of the recommendations.*** ([Amazon 2017](https://www.computer.org/csdl/mags/ic/2017/03/mic2017030012.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Propuesta para resolver el problema\n",
    "\n",
    "Resolvemos en cambio el problema de  **prediccion del proximo producto de la secuencia (dados los anteriores)**.\n",
    "\n",
    "Una vez entrenado el modelo, usamos las probabilidades del modelo sobre el proximo producto para generar candidatos de recomendacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Propuesta para resolver el problema: caveat\n",
    "\n",
    "**Observacion**: Este problema **no es equivalente al original** (maximizar CTR):\n",
    "- Cruzamos los dedos para que resolver bien el nuevo problema implique resolver bien el original.\n",
    "- La ventaja es que la metrica del problema nuevo (precision) la podemos calcular **facil a partir de datos historicos** (offline), mientras que el CTR no!\n",
    "\n",
    "***It is important to emphasize that recommendation often involves solving a surrogate problem and transferring the result to a particular context. A classic example is the assumption that accurately predicting ratings leads to effective movie recommendations. We have found that the choice of this surrogate learning problem has an outsized importance on performance in A/B testing but is very difficult to measure with offline experiments*** ([YouTube 2016](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Formalizando\n",
    "\n",
    "Sea:\n",
    "\n",
    "- $I$: el conjunto de items/productos ($|I| = n$)\n",
    "- $S^{(i)}$: la $i$-esima sesion de entre $m$, con $S^{(i)} = (S_1^{(i)}, \\dots, S_{l_i}^{(i)}) \\in I^{l_i}$.\n",
    "\n",
    "Buscamos una funcion (modelo)\n",
    "\n",
    "$$f : \\cup_k I^k \\rightarrow Prob(I)$$\n",
    "\n",
    "que dada la secuencia de productos vistos por el usuario, nos de una distribucion de probabilidad sobre el siguiente producto. \n",
    "\n",
    "**Objetivo**: maximizar la precision (o precision at $K$, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cadenas de Markov\n",
    "\n",
    "- Considerar solo el ultimo producto.\n",
    "- Se calcula la matriz de probabilidad de transicion entre productos.\n",
    "\n",
    "Ej: Dadas sesiones:\n",
    "- $\\text{ipod} \\rightarrow \\text{auriculares}$\n",
    "- $\\text{celular} \\rightarrow \\text{auriculares} \\rightarrow \\text{memoria 16GB}$\n",
    "- $\\text{celular} \\rightarrow \\text{memoria 16GB} \\rightarrow \\text{auriculares}$\n",
    "\n",
    "El modelo es:\n",
    "\n",
    "|actual\\siguiente|ipod|celular|auriculares|memoria 16GB|\n",
    "|-|-|-|-|-|\n",
    "|ipod|0.0|0.0|1.0|0.0|\n",
    "|celular|0.0|0.0|0.5|0.5|\n",
    "|auriculares|0.0|0.0|0.0|1.0|\n",
    "|memoria 16GB|0.0|0.0|1.0|0.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cadenas de Markov: Problemas\n",
    "\n",
    "- Las probabilidades de transicion son solo **estimaciones de la realidad** y son pesimas para los productos que aparecen pocas veces.\n",
    "- Otra forma de verlo: Sea $t$ la cantidad promedio de transiciones relevantes desde un producto a otro. Entonces el modelo de Markov tiene que aprender $tN$ parametros. Es mucho! Y la mayoria de ellos se infiere a partir de poca data $\\Rightarrow$ overfitting.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/long_tail.jpg\" width=\"400\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cadenas de Markov Factorizadas\n",
    "\n",
    "Paper: [Rendle 2010](https://www.ismll.uni-hildesheim.de/pub/pdfs/RendleFreudenthaler2010-FPMC.pdf)\n",
    "\n",
    "Motivacion: Supongamos que tenemos tres sesiones:\n",
    "- $\\text{celular} \\rightarrow \\text{auricular 1} \\rightarrow \\text{memoria 16 GB}$\n",
    "- $\\text{celular} \\rightarrow \\text{auricular 1} \\rightarrow \\text{memoria 32 GB}$\n",
    "- $\\text{celular} \\rightarrow \\text{auricular 2} \\rightarrow \\text{memoria 16 GB}$\n",
    "\n",
    "Estaria bueno que el modelo se de cuenta solo de que auricular 1 y auricular 2 son **'lo mismo'**. Si lo logramos, todas las transiciones desde/hacia auricular 1 van a contribuir a las estimaciones de las probabilidades de transicion de auricular 2 y viceversa.\n",
    "\n",
    "- Asi aprenderiamos que de auricular 2 podemos transicionar a memoria 32 GB.\n",
    "- Es como si aumentaramos nuestro dataset $\\Rightarrow$ reduzco overfitting, generalizo mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Digresion: Embeddings\n",
    "\n",
    "Dado un conjunto $X$ (ej: de productos), un **embedding** es una funcion $emb : X \\rightarrow \\mathbb R^k$.\n",
    "- La idea es que con un embedding bueno, elementos 'semanticamente similares' van a parar a vectores similares.\n",
    "- $k$ se llama la **dimension** del embedding.\n",
    "- Hay que definir una nocion de 'similitud' en $\\mathbb R^k$, tipicamente el producto interno. ($sim(u, v) = \\left<u, v\\right>$)\n",
    "\n",
    "Ejemplo: embeddings de dimension 2 para palabras:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/embeddings.png\" width=\"500\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cadenas de Markov Factorizadas: Embeddings\n",
    "\n",
    "- Para cada producto $i$ aprenderemos un embedding $v_i \\in \\mathbb R^k$. La idea va a ser que la probabilidad de transicionar de $i$ a $j$ sea proporcional a $sim(v_i, v_j)$ \n",
    "- En el ejemplo anterior, buscamos obtener algo como:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/embedding_productos.png\" width=\"400\">\n",
    "</center>\n",
    "\n",
    "- Asi, por mas que no observemos una transicion de auricular 2 a memoria 32 GB, si auricular 1 y auricular 2 van a parar cerca, deducimos la transicion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cadenas de Markov Factorizadas: Formalizacion\n",
    "\n",
    "Dados los embeddings $v_i$, la probabilidad de transicion del producto $i$ al $j$ en el modelo es\n",
    "\n",
    "$$P(j | i) \\propto\n",
    "e^{\\left<v_i, v_j\\right>}$$\n",
    "\n",
    "O sea,\n",
    "\n",
    "$$P(j | i) = \\frac{e^{\\left<v_i, v_j\\right>}}{\\sum_{k} e^{\\left<v_i, v_k\\right>}}$$\n",
    "\n",
    "tambien conocido como un **softmax**.\n",
    "\n",
    "Ahora maximizar la probabilidad de los datos (bajo el modelo generativo asociado):\n",
    "\n",
    "\\begin{align}\n",
    "\\arg \\max_{v_1,\\dots,v_n} P(S^{(1)}, \\dots, S^{(m)}) = \\arg \\max_{v_1,\\dots,v_n}  \\prod_{i = 1}^m \\prod_{j = 1}^{l_i - 1} P({S_j^{(i)}, S_{j+1}^{(i)}})\n",
    "\\end{align}\n",
    "\n",
    "O sea, hacer maximum likelihood.\n",
    "\n",
    "***This factorization approach results\n",
    "in less parameters and due to generalization to a\n",
    "better quality than full parametrized models.*** ([Rendle 2010](https://www.ismll.uni-hildesheim.de/pub/pdfs/RendleFreudenthaler2010-FPMC.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cadenas de Markov Factorizadas: Notas\n",
    "\n",
    "- Es muy parecido al skip-gram model para word embeddings. ([Mikolov 2013](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf))\n",
    "\n",
    "- Se puede tener dos embeddings $u_i, v_i$ para cada producto, y definir en cambio:\n",
    "\n",
    "$$P(j | i) \\propto\n",
    "e^{\\left<u_i, v_j\\right>}$$\n",
    "\n",
    "- Entrenar con ranking loss suele andar mejor (se correlaciona mejor con la metrica de interes, como AUC) ([Rendle 2009](https://arxiv.org/pdf/1205.2618.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cadenas de Markov Factorizadas: Resultados\n",
    "\n",
    "<center>\n",
    "<img src=\"images/FMC2.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "([Rendle 2010](https://www.ismll.uni-hildesheim.de/pub/pdfs/RendleFreudenthaler2010-FPMC.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Recap\n",
    "\n",
    "- Cadenas de Markov: Estimo $P(j|i)$ sin restricciones.\n",
    "- Cadenas de Markov Factorizadas: Restrinjo $P$ tal que $P(j | i) \\propto\n",
    "e^{\\left<v_i, v_j\\right>}$ $\\Rightarrow$ + bias, - variance $\\Rightarrow$ - overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Redes Recurrentes\n",
    "- Generalizan las Cadenas de Markov Factorizadas.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/RNN.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "- $i_t$ = input en tiempo $t$.\n",
    "- $h_t$ = estado en tiempo $t$ $= f(h_{t - 1}, i_t)$ para alguna $f$. Ejemplos tipicos de $f$: GRU, LSTM.\n",
    "- $o_t$ = output en tiempo $t$ $= g(h_t)$ para alguna $g$. Ejemplos tipicos de $g$: softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cadenas de Markov Factorizadas como Redes Recurrentes\n",
    "\n",
    "<center>\n",
    "<img src=\"images/FMC_as_RNN.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "- $i_t = v_t$\n",
    "- $h_t = f(h_{t - 1}, i_t) = i_t$\n",
    "- $o_t = g(h_t) = softmax(\\left<h_t, v_1\\right>, \\dots, \\left<h_t, v_m\\right>) = softmax(V h_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Recurrentes: GRU\n",
    "\n",
    "<center>\n",
    "<img src=\"images/RNN.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "- $h_0 = 0$\n",
    "- $i_t = v_t$\n",
    "- $h_t = f(h_{t - 1}, i_t) = (1 - z_t) \\odot h_{t-1} + z_t \\odot \\sigma_h(W_h x_t + U_h(r_t \\odot h_{t-1}) + b_h)$ donde\n",
    "$$z_t = \\sigma_g(W_z x_t + U_z h_{t-1} + b_z)$$\n",
    "$$r_t = \\sigma_g(W_r x_t + U_r h_{t-1} + b_r)$$\n",
    "$$\\sigma_g(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "$$\\sigma_h(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$$\n",
    "- $o_t = g(h_t) = softmax(\\left<h_t, v_1\\right>, \\dots, \\left<h_t, v_m\\right>) = softmax(V h_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Recurrentes: Algo Intermedio\n",
    "\n",
    "<center>\n",
    "<img src=\"images/RNN.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "Promedio ponderado de la historia:\n",
    "\n",
    "- $h_0 = v_1$\n",
    "- $i_t = v_t$\n",
    "- $h_t = \\frac{i_t + h_{t-1}}{2}$\n",
    "- $o_t = g(h_t) = softmax(\\left<h_t, v_1\\right>, \\dots, \\left<h_t, v_m\\right>) = softmax(V h_t)$\n",
    "\n",
    "La diferencia entre esto y la Cadena de Markov Factorizada es que aca usamos\n",
    "\n",
    "$$\\frac{v_1}{2^{t-1}} + \\frac{v_2}{2^{t-1}} + \\frac{v_3}{2^{t-2}} + \\dots + \\frac{v_t}{2}$$\n",
    "\n",
    "para el estado en vez de $v_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Recurrentes: Resultados - Baselines\n",
    "\n",
    "<center>\n",
    "<img src=\"images/baselines.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "([Hidasi 2016](https://arxiv.org/pdf/1511.06939.pdf))\n",
    "\n",
    "- **POP** es recomendar lo mas popular.\n",
    "- **S-POP** es recomendar lo mas popular de la sesion.\n",
    "- **Item-KNN** es el item-knn discutido, mirando el ultimo producto nada mas para hacer la recomendacion.\n",
    "- **BPR-MF** es como la red recurrente anterior pero tomando promedio no ponderado, y entrenando con ranking loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Recurrentes: Resultados\n",
    "\n",
    "<center>\n",
    "<img src=\"images/resultados_rnn.png\" width=\"600\">\n",
    "</center>\n",
    "\n",
    "([Hidasi 2016](https://arxiv.org/pdf/1511.06939.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes (No) Recurrentes: YouTube 2016\n",
    "\n",
    "<center>\n",
    "<img src=\"images/reco_funnel.png\" width=\"400\">\n",
    "</center>\n",
    "\n",
    "([YouTube 2016](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes (No) Recurrentes: YouTube 2016 - Candidate Generation Network\n",
    "\n",
    "<center>\n",
    "<img src=\"images/youtube_2016_candidate_generation.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "([YouTube 2016](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes (No) Recurrentes: YouTube 2016 - Candidate Generation Network - Resultados\n",
    "\n",
    "<center>\n",
    "<img src=\"images/generator_network_results.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "([YouTube 2016](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes (No) Recurrentes: YouTube 2016 - Ranking Network\n",
    "\n",
    "<center>\n",
    "<img src=\"images/youtube_2016_ranking.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "([YouTube 2016](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes (No) Recurrentes: YouTube 2016 - Ranking Network - Resultados\n",
    "\n",
    "<center>\n",
    "<img src=\"images/ranking_network_results.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "([YouTube 2016](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Referencias\n",
    "\n",
    "- [Two Decades of Recommender Systems at Amazon.com (Amazon 2017)](https://www.computer.org/csdl/mags/ic/2017/03/mic2017030012.pdf)\n",
    "- [Item-to-Item Collaborative Filtering (Amazon 2003)](https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf)\n",
    "- [Session-Based Recommendations with Recurrent Neural Networks (Hidasi 2016)](https://arxiv.org/pdf/1511.06939.pdf)\n",
    "- [Deep Neural Networks for YouTube Recommendations (YouTube 2016)](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf)\n",
    "- [Factorizing Personalized Markov Chains for Next-Basket Recommendation (Rendle 2010)](https://www.ismll.uni-hildesheim.de/pub/pdfs/RendleFreudenthaler2010-FPMC.pdf)\n",
    "- [Distributed Representations of Words and Phrases\n",
    "and their Compositionality (Mikolov 2013)](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "- [BPR: Bayesian Personalized Ranking from Implicit Feedback (Rendle 2009)](https://arxiv.org/pdf/1205.2618.pdf)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
